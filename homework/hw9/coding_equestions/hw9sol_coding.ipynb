{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d33bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbfbe9f",
   "metadata": {},
   "source": [
    "# Multiplicative Weights Update\n",
    "\n",
    "In this notebook we will explore alternate solutions to the experts question and show why they are inferior to the multiplicative weights update algorithm covered in class. This notebook has multiple subparts. In each subpart, we provide some expert picking strategy, and your job is to implement a strategy the adversary will use to maximize regret. \n",
    "\n",
    "In this notebook, the formula for regret we use is $R = \\frac{1}{T}(\\sum\\limits_{t=1}^{T}c_{i(t)}^t - \\min\\limits_{1\\leq i \\leq n}\\sum\\limits_{t=1}^{T}c_i^t)$\n",
    "\n",
    "Where $T$ is the total number of days, $i(t)$ is the expert you choose on day $t$, and $c_i^t$ is the cost of expert $i$ on day $t$.\n",
    "\n",
    "\n",
    "\n",
    "First, let's understand the functions you'll be working with:\n",
    "\n",
    "- `pick_[strategy](costs_so_far, day, experts_picked_so_far, weights = [])`: returns the index of the expert we should pick on the current day, given the history of the costs accrued by each expert\n",
    "\n",
    "\n",
    "- `adversary_[strategy](costs_so_far, day, experts_picked_so_far, weights = [])`: returns a loss array containing the new costs on the current day given the losses so far and a list of experts picked\n",
    "\n",
    "\n",
    "- `compute_regret(strategy, adversary, n, num_experts, weights = [])`: calculates the total regret given a strategy used to pick experts, the adversaries actions, and the number of days n\n",
    "\n",
    "The chooser will use the `pick_[strategy]` function to choose experts on each day. The adversary will use the `adversary_[strategy]` function to assign the losses to each expert on each day. The `compute_regret` function will then compute the total regret given the two strategies.\n",
    "\n",
    "For example, let's observe the following strategy:\n",
    "\n",
    "## 1) Always pick the same expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eebc5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_same(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    Returns the index of the expert we should pick on the current day, \n",
    "    given the history of the costs accrued by each expert\n",
    "    \n",
    "    In this function, we always pick expert 0 regardless of costs\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "                  \n",
    "    day: an integer representing the current day\n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic\n",
    "    '''\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f7a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversary_pick_same(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    returns a loss array containing the new costs on the current day given the losses \n",
    "    so far and a list of experts picked\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "                  \n",
    "    day: an integer representing the current day \n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic\n",
    "    '''\n",
    "    num_experts = len(costs_so_far)\n",
    "    new_costs = [1] + [0 for i in range(num_experts - 1)]\n",
    "    return new_costs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_regret(strategy, adversary, n, num_experts, weights = []):\n",
    "    \"\"\"\n",
    "    calculates the total regret given a strategy used to pick experts, the adversaries \n",
    "    actions, and the number of days n\n",
    "    \n",
    "    args:\n",
    "    strategy(costs_so_far, day): a function which returns the index of the expert we should pick on the \n",
    "        current day, given the history of the costs accrued by each expert \n",
    "    \n",
    "    adversary(costs_so_far, day, experts_picked_so_far): a function which returns a cost matrix including \n",
    "        the new costs on the current day given the costs so far and a list of experts picked\n",
    "    \n",
    "    n: number of days we run the algorithm \n",
    "    num_experts: an integer representing the number of experts to choose from\n",
    "    \n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic\n",
    "    \n",
    "    return: a number representing the loss accrued\n",
    "    \"\"\"\n",
    "    costs = [[] for i in range(num_experts)]\n",
    "    experts_picked = []\n",
    "    \n",
    "    for day in range(n):\n",
    "        experts_picked.append(strategy(costs, day, experts_picked, weights))\n",
    "        new_costs = adversary(costs, day, experts_picked, weights)\n",
    "        for i in range(num_experts):\n",
    "            costs[i].append(new_costs[i])\n",
    "        \n",
    "    total_cost = sum([costs[experts_picked[day]][day] for day in range(n)])\n",
    "    \n",
    "    expert_costs = [sum(costs[i]) for i in range(num_experts)]\n",
    "    best_expert_cost = min(expert_costs)\n",
    "\n",
    "    return (total_cost - best_expert_cost)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d64fe",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "If the adversary knows that the same expert will be picked every day, the adversary can simply maximize regret by giving that one expert a loss of one everyday and everyone else a loss of zero. If we run the `compute_regret` function below, we see that our regret given 100 experts and 200 days is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_regret(pick_same, adversary_pick_same, 200, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f16c3c",
   "metadata": {},
   "source": [
    "Below we provide 4 different expert picking strategies which are far inferior to multiplicative weights update. We have implemented each expert picking strategy already. Your job is to implement the adversary's strategy to guarantee the highest possible (or highest expected) loss for that expert picking strategy. Each subpart is seperate from one another, so your adversary strategy only needs to consider the expert picking strategy in that subpart.\n",
    "\n",
    "## 2) Picking the best expert from the previous day\n",
    "This expert picking strategy only looks at the loss from the previous day and simply picks the best expert based on that loss. You may assume the following about this strategy.\n",
    "\n",
    "- On day 0 when you pick the first expert, you pick expert 0.\n",
    "- From day 1 and onwards, if multiple experts are tied for the best from the previous day, you pick an expert uniformly at random.\n",
    "- The lowest non-zero loss that an expert can have is 0.1 (ie if the adversary can set the loss of an expert as 0 or any number between 0.1 and 1.0).\n",
    "\n",
    "The expert picking strategy is implemented below. Implement a strategy the adversary can use to guarantee a regret of 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_previous_best(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    Returns the index of the expert we should pick on the current day, \n",
    "    given the history of the costs accrued by each expert\n",
    "    \n",
    "    In this function, we always pick the best expert from the previous day\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "\n",
    "    day: an integer representing the current day\n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic\n",
    "    '''\n",
    "    if day == 0:\n",
    "        return 0\n",
    "    \n",
    "    num_experts = len(costs_so_far)\n",
    "    prev_day_costs = [costs_so_far[i][day - 1] for i in range(num_experts)]\n",
    "    min_cost = min(prev_day_costs)\n",
    "    previous_best = [i for i in range(num_experts) if prev_day_costs[i]== min_cost]\n",
    "    return random.choice(previous_best)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversary_previous_best(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    returns a loss array containing the new costs on the current day given the losses \n",
    "    so far and a list of experts picked\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "                  \n",
    "    day: an integer representing the current day \n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic\n",
    "    '''\n",
    "    num_experts = len(costs_so_far)\n",
    "    if day % 2 == 0:\n",
    "        return [1, 0] + [0.1 for i in range(num_experts - 2)]\n",
    "    else: # day % 2 == 1\n",
    "        return [0, 1] + [0.1 for i in range(num_experts - 2)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a4285",
   "metadata": {},
   "source": [
    "## Verifier\n",
    "We run the `compute_regret` function on your strategies to verify that it achieves a regret of 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51086c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    regret = compute_regret(pick_previous_best, adversary_previous_best, 5, 5)\n",
    "    assert regret <= 0.9, f\"your algorithm achieved a regret of {regret}, make sure your losses are in the valid range\"\n",
    "    assert regret >= 0.9, f\"your algorithm achieved a regret of {regret}, try creating a better strategy\"\n",
    "    \n",
    "    \n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2288a2ad",
   "metadata": {},
   "source": [
    "## 3) picking uniformly at random\n",
    "\n",
    "In this strategy, you always pick an expert uniformly at random, independent of the losses each expert accrues and independent of the experts you picked on the previous day.\n",
    "\n",
    "The expert picking strategy is implemented below. Implement a strategy the adversary can use to guarantee an expected regret of $\\frac{n - 1}{n}$, where $n$ is the number of experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c27658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_uniform_random(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    returns the index of the expert we should pick on the current day, \n",
    "    given the history of the costs accrued by each expert\n",
    "    \n",
    "    In this function, we always pick an expert uniformly at random regardless of the costs.\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "\n",
    "   day: an integer representing the current day\n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic\n",
    "    '''\n",
    "    return random.randint(0,len(costs_so_far) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversary_pick_uniform(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    returns a cost matrix including the new costs on the current day given the costs \n",
    "    so far and a list of experts picked\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "                  \n",
    "    day: an integer representing the current day \n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic    \n",
    "    '''    \n",
    "    num_experts = len(costs_so_far)\n",
    "    new_costs = [0] + [1 for i in range(num_experts - 1)]\n",
    "    return new_costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b8111",
   "metadata": {},
   "source": [
    "## Verifier\n",
    "We run the `compute_regret` function on your strategies to verify that it achieves an expected regret of $\\frac{n-1}{n}$. Since this is a nondeterministic strategy, the regrets you end up getting may slightly deviate from $\\frac{n-1}{n}$; thus, our tests simply require your regret to be within one percent of $\\frac{n-1}{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(10,100,10):\n",
    "    total = 0\n",
    "    for i in range(10):\n",
    "        total += compute_regret(pick_uniform_random, adversary_pick_uniform, 1000, n)\n",
    "    total /= 10\n",
    "    assert abs(total - ((n-1)/n)) < 0.01, f\"your strategy has a regret of {total}, but we expected {(n-1)/n}\"\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326f496",
   "metadata": {},
   "source": [
    "## 4) picking with a distribution\n",
    "\n",
    "In this strategy, you will randomly pick each expert i with probability $p_i$, independent of the losses each expert accrues and independent of the experts you picked on the previous day. These probabilities are provided in the `weights` parameter. `weights` is also passed into the adversary function, so you can use it to create a strategy for the adversary.\n",
    "\n",
    "The expert picking strategy is implemented below. Implement a strategy the adversary can use to guarantee an expected regret of 1 - $\\min_i(p_i)$, where $p_i$ is the probability of picking expert i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0656f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_with_distribution(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    returns the index of the expert we should pick on the current day, \n",
    "    given the history of the costs accrued by each expert\n",
    "    \n",
    "    In this function, we always pick expert 0 regardless of costs\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "\n",
    "    day: an integer representing the current day\n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic    '''\n",
    "    return random.choices([i for i in range(len(costs_so_far))], weights=weights)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversary_pick_distribution(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    returns a cost matrix including the new costs on the current day given the costs \n",
    "    so far and a list of experts picked\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "\n",
    "    day: an integer representing the current day \n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic\n",
    "    '''\n",
    "    num_experts = len(costs_so_far)\n",
    "    min_expert = weights.index(min(weights))\n",
    "\n",
    "    new_costs = [1 for i in range(num_experts)]\n",
    "    new_costs[min_expert] = 0\n",
    "    return new_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef27f2c",
   "metadata": {},
   "source": [
    "## Verifier\n",
    "We run the `compute_regret` function on your strategies to verify that it achieves an expected regret of 1 - $\\min_i(p_i)$. Since this is a nondeterministic strategy, the regrets you end up getting may slightly deviate from 1 - $\\min_i(p_i)$; thus, our tests simply require your regret to be within one percent of 1 - $\\min_i(p_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_experts in range(10,100,10):\n",
    "    for i in range(10):\n",
    "\n",
    "        #computes the probability of picking each expert\n",
    "        weights = [random.randint(0,50) for i in range(num_experts)]\n",
    "        total = sum(weights)\n",
    "        weights = [w/total for w in weights]\n",
    "\n",
    "        total_regret = 0\n",
    "        for i in range(30):\n",
    "            total_regret += compute_regret(pick_with_distribution, adversary_pick_distribution, 100, num_experts, weights)\n",
    "        total_regret /= 30\n",
    "        assert abs(total_regret - (1 - min(weights))) < 0.01, f\"your strategy has a regret of {total_regret}, but we expected {(1 - min(weights))}\"\n",
    "\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd17f5bf",
   "metadata": {},
   "source": [
    "## 5) Picking the best expert so far\n",
    "This expert picking strategy picks the expert with the smallest total loss so far. If there are ties, pick the lowest indexed one.\n",
    "\n",
    "The expert picking strategy is implemented below. Implement a strategy the adversary can use to guarantee a regret of $\\frac{n-1}{n}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aed480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_best_so_far(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    returns the index of the expert we should pick on the current day, \n",
    "    given the history of the costs accrued by each expert\n",
    "    \n",
    "    Picks the best expert so far, if there are ties, pick the lowest indexed one.\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "\n",
    "    day: an integer representing the current day\n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic\n",
    "    '''\n",
    "    total_loss = [sum(expert_loss) for expert_loss in costs_so_far]\n",
    "    return total_loss.index(min(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversary_best_so_far(costs_so_far, day, experts_picked_so_far, weights = []):\n",
    "    '''\n",
    "    returns a cost matrix including the new costs on the current day given the costs \n",
    "    so far and a list of experts picked\n",
    "    \n",
    "    args:\n",
    "    costs_so_far: a list of list of integers. Each list k of integers represents \n",
    "                  the costs expert k accrued across all previous days.\n",
    "                  \n",
    "                  For example: \n",
    "                  [[1, 0, 1, 0.5],                                \n",
    "                   [0.5, 1, 0.2, 0.3],\n",
    "                   [0.1, 1, 1, 0.8]]\n",
    "                  means expert 0 accrued the costs 1, 0, 1, and 0.5 on days 0, 1, 2, 3 respectively.\n",
    "                 \n",
    "    day: an integer representing the current day \n",
    "    experts_picked_so_far: a lists of integers representing a list of experts we picked on each day\n",
    "    weights = a non-empty list of numbers representing the weights used to pick experts if the strategy is \n",
    "        not deterministic\n",
    "    '''\n",
    "    num_experts = len(costs_so_far)\n",
    "    if len(costs_so_far[0]) == 0:\n",
    "        new_costs = [0 for i in range(num_experts)]\n",
    "        new_costs[0] = 1\n",
    "        return new_costs\n",
    "    total_loss = [sum(expert_loss) for expert_loss in costs_so_far]\n",
    "    min_expert = total_loss.index(min(total_loss))\n",
    "    new_costs = [1 if i == min_expert else 0 for i in range(num_experts)] \n",
    "    return new_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2a601",
   "metadata": {},
   "source": [
    "## Verifier\n",
    "We run the `compute_regret` function on your strategies to verify that it achieves an expected regret of $\\frac{n-1}{n}$. Since this is a nondeterministic strategy, the regrets you end up getting may slightly deviate from 1 - $\\min_i(p_i)$; thus, our tests simply require your regret to be within one percent of $\\frac{n-1}{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_experts in range(10, 100, 10):\n",
    "    total = 0\n",
    "    for i in range(20):\n",
    "        total += compute_regret(pick_best_so_far, adversary_best_so_far, 100, num_experts)\n",
    "    total /= 20\n",
    "    assert abs(total - ((num_experts-1)/num_experts)) < 0.01, f\"your strategy has a regret of {total}, but we expected {((num_experts-1)/num_experts)}\"\n",
    "\n",
    "print(\"success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
